<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="程序小栈">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->

    <meta name="keywords" content="数据可视化,爬虫">


    <meta name="description" content="1.  整体思路流程
通过URL获取说要爬取的页面的响应信息（Requests库的使用）
通过python中的解析库来对response进行结构化解析（BeautifulSoup库的使用）
通过...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>学习用Python制作一个简易爬虫并作初步的数据可视化 | 程序小栈</title>


    <link rel="alternate" href="/atom.xml" title="程序小栈" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    





    

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-image:url(/img/start.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="WeiQingcai">
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                <h2> 兜里有糖心不慌 </h2>
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">程序小栈</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/大数据与网络安全/"><i class="fa "></i>大数据与网络安全</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/Android/"><i class="fa "></i>Android</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/数据结构与算法/"><i class="fa "></i>数据结构与算法</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>时间轴</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="学习用Python制作一个简易爬虫并作初步的数据可视化">
            
	            学习用Python制作一个简易爬虫并作初步的数据可视化
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/大数据与网络安全/">大数据与网络安全</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/数据可视化/">数据可视化</a> <a class="tag-link" href="/tags/爬虫/">爬虫</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/08/01</span>
        </span>
        
            <span class="fa-wrap">
                <i class="fa fa-eye"></i>
                <span id="busuanzi_value_page_pv"></span>
            </span>
        
    
</div>
            
            
    </div>
    
    <div class="post-body post-content">
        <h2 id="1-整体思路流程"><a href="#1-整体思路流程" class="headerlink" title="1.  整体思路流程"></a>1.  整体思路流程</h2><ol>
<li>通过URL获取说要爬取的页面的响应信息（Requests库的使用）</li>
<li>通过python中的解析库来对response进行结构化解析（BeautifulSoup库的使用）</li>
<li>通过对解析库的使用和对所需要的信息的定位从response中获取需要的数据（selecter和xpath的使用）</li>
<li>将数据组织成一定的格式进行保存（MongoDB的使用）</li>
<li>通过对数据库中的数据进行筛选和组织，进行数据可视化的初步展示（HighCharts库的使用）</li>
</ol>
<h2 id="2-简单代码演示"><a href="#2-简单代码演示" class="headerlink" title="2.  简单代码演示"></a>2.  简单代码演示</h2><h3 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1.  准备工作"></a>1.  准备工作</h3><p>下载并安装所需要的python库，包括：</p>
<ul>
<li><p>requests库：用于向指定url发起请求</p>
</li>
<li><p>BeautifulSoup库：用于解析返回的网页信息</p>
</li>
<li><p>lxml库：用于解析网页返回结果</p>
</li>
<li><p>pymongo库：用于实现python对MongoDB的操作</p>
</li>
<li><p>HighCharts库：对于数据进行初步可视化的展示</p>
</li>
</ul>
<p>所有以上的库都直接可以使用pip命令进行下载</p>
<h3 id="2-对所需要的网页进行请求并解析返回的数据"><a href="#2-对所需要的网页进行请求并解析返回的数据" class="headerlink" title="2.  对所需要的网页进行请求并解析返回的数据"></a>2.  对所需要的网页进行请求并解析返回的数据</h3><p>对于想要做一个简单的爬虫而言，这一步其实很简单，主要是通过requests库来进行请求，然后对返回的数据进行一个解析，解析之后通过对于元素的定位和选择来获取所需要的数据元素，进而获取到数据的一个过程。</p>
<p><strong>一个简单的网络爬虫示例</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#58同城的二手市场主页面</span><br><span class="line">start_url = &apos;http://bj.58.com/sale.shtml&apos;</span><br><span class="line">url_host = &apos;http://bj.58.com&apos;</span><br><span class="line">#定义一个爬虫函数来获取二手市场页面中的全部大类页面的连接</span><br><span class="line">def get_channel_urls(url):</span><br><span class="line">	#使用Requests库来进行一次请求</span><br><span class="line">    web_data = requests.get(url)</span><br><span class="line">    #使用BeautifulSoup对获取到的页面进行解析</span><br><span class="line">    soup = BeautifulSoup(web_data.text, &apos;lxml&apos;)</span><br><span class="line">    #根据页面内的定位信息获取到全部大类所对应的连接</span><br><span class="line">    urls = soup.select(&apos;ul.ym-submnu &gt; li &gt; b &gt; a&apos;)</span><br><span class="line">    #作这两行处理是因为有的标签有链接，但是却是空内容</span><br><span class="line">    for link in urls:</span><br><span class="line">        if link.text.isspace():</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            page_url = url_host + link.get(&apos;href&apos;)</span><br><span class="line">            print(page_url)</span><br></pre></td></tr></table></figure>
<p>对于定位页面中所需标签位置的方法有很多种，可以自己根据页面的情况多进行尝试。<br><img src="https://img-blog.csdn.net/20180518200734337?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dxY19DU0RO/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="58同城中关于大类连接的定位"></p>
<p>可以看到所有的大类链接都位于ul标签 &gt; li标签 &gt; b标签 &gt; a标签<br>故此我们可以使用上边代码中的方式来获取全部的大类标签</p>
<pre><code>注 ： 在进行标签定位时 ‘&gt;’ 符号表示上一个标签的严格的子标签，而‘空格’ 符号表示上一个标签的子标签或者子孙标签

例如：

对于ul.ym-submnu &gt; li而言，表示class属性为ym-submnu的ul标签的子标签li，则选出来的li只能是ul.ym-submnu的子标签

若是ul.ym-submnu li而言，表示class属性为ym-submnu的ul标签的子孙标签，即选出来的li可能是ul.ym-submnu的子标签或者子孙标签
</code></pre><p><strong>爬取结果部分截图</strong><br><img src="https://img-blog.csdn.net/20180518202237248?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dxY19DU0RO/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="爬取结果部分截图"></p>
<p>以上就是一个简单的网页爬虫的制作过程，我们可以通过定义不同的爬虫来实现爬取不同页面的信息，并通过程序的控制来实现一个自动化爬虫。</p>
<h3 id="3-对爬取到的数据进行存储和初步的可视化显示"><a href="#3-对爬取到的数据进行存储和初步的可视化显示" class="headerlink" title="3.  对爬取到的数据进行存储和初步的可视化显示"></a>3.  对爬取到的数据进行存储和初步的可视化显示</h3><p>python中用于数据的可视化显示的库有很多，我们可以根据需要来选择不同的库。数据的存储推荐使用MongoDB的方式，比起Mysql来说有很大的便利性，更适合大规模的数据整理。数据的可视化使用了HighCharts，可以直接在网页上显示出数据结果。</p>
<ol>
<li><p>关于MongoDB数据库的入门使用可以参看这篇博文——-<a href="https://blog.csdn.net/wqc_CSDN/article/details/80307222" target="_blank" rel="noopener">MongoDB入门及问题总结</a></p>
</li>
<li><p>关于HighCharts的使用可以参看其官网<a href="https://www.hcharts.cn/docs/start-introduction" target="_blank" rel="noopener">HighCharts官网使用文档</a></p>
</li>
</ol>
<p><strong>首先：</strong>在程序中创建一个MongoDB的连接用于存储数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">client = pymongo.MongoClient(&apos;localhost&apos;, 27017)#链接MongoDB</span><br><span class="line">DB_58 = client[&apos;DB_58&apos;]#创建一个数据库</span><br><span class="line">url_list_tab = DB_58[&apos;url_list_tab&apos;]#创建用于存储全部商品url的文档</span><br><span class="line">item_detail_tab = DB_58[&apos;item_detail_tab&apos;]#创建用于存储商品详情的文档</span><br></pre></td></tr></table></figure></p>
<p><strong>然后：</strong>通过之前获取到的每个分类的链接，来爬取该分类下的全部的商品链接</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 从每个频道获取全部的商品链接</span><br><span class="line">def get_liks_from(channel, pages, who_sells=0):</span><br><span class="line">    # http://bj.58.com/diannao/0/pn5/</span><br><span class="line">    list_view = &apos;&#123;&#125;&#123;&#125;/pn&#123;&#125;/&apos;.format(channel, str(who_sells), str(pages))</span><br><span class="line">    web_data = requests.get(list_view)</span><br><span class="line">    time.sleep(2)</span><br><span class="line">    soup = BeautifulSoup(web_data.text, &apos;lxml&apos;)</span><br><span class="line">    #爬取个人商家列表</span><br><span class="line">    if soup.find(&apos;td&apos;,&apos;t&apos;):</span><br><span class="line">        for link in soup.select(&apos;.zzinfo &gt; td.t &gt; a.t&apos;):</span><br><span class="line">            item_link = link.get(&apos;href&apos;).split(&apos;?&apos;)[0]</span><br><span class="line">            #去除掉跳转类型的连接</span><br><span class="line">            if item_link != &apos;http://jump.zhineng.58.com/jump&apos;:</span><br><span class="line">	            #得到想要的商品页面链接之后保存在数据库中</span><br><span class="line">                url_list_tab.insert_one(&#123;&apos;url&apos;: item_link&#125;)</span><br><span class="line">                print(item_link)</span><br><span class="line">    else:</span><br><span class="line">        pass</span><br><span class="line">    #爬取店铺商家列表</span><br><span class="line">    if soup.find(&apos;div&apos;,&apos;left&apos;):</span><br><span class="line">        for link in soup.select(&apos;a.title&apos;):</span><br><span class="line">            item_link = link.get(&apos;href&apos;)</span><br><span class="line">            #去除掉跳转类型的连接</span><br><span class="line">            if item_link != &apos;http://jump.zhineng.58.com/jump&apos;:</span><br><span class="line">	            #得到想要的商品页面链接之后保存在数据库中</span><br><span class="line">                url_list_tab.insert_one(&#123;&apos;url&apos;: item_link&#125;)</span><br><span class="line">                print(item_link)</span><br><span class="line">    else:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<p>由于58个人卖家的二手信息会跳转到转转这个平台，所以需要根据页面中的标签来判断是那种类型的页面</p>
<p><strong>第三步：</strong>在获取到全部的商品的url之后需要对商品的详情进行爬取，同时保存在数据库中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 爬取商品详情页的信息</span><br><span class="line">def get_item_info(url):</span><br><span class="line">    if &apos;short.58.com&apos; not in url:</span><br><span class="line">	    #加一个延时，爬取太快58会出来验证码</span><br><span class="line">        time.sleep(1)</span><br><span class="line">        web_data = requests.get(url)</span><br><span class="line">        soup = BeautifulSoup(web_data.text, &apos;lxml&apos;)</span><br><span class="line">        # 根据页面中的独特元素来辨别是哪个版本的网页</span><br><span class="line">        if soup.find(&apos;span&apos;, &apos;want_left&apos;):</span><br><span class="line">            parse_person_item_info(soup)</span><br><span class="line">        else:</span><br><span class="line">            parse_shop_item_info(soup)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;error with url : &apos;+url)</span><br><span class="line"></span><br><span class="line"># 解析个人卖家的商品详情</span><br><span class="line">def parse_person_item_info(soup):</span><br><span class="line">    item_detail_tab.insert_one(&#123;</span><br><span class="line">        &apos;title&apos;: soup.select(&apos;h1.info_titile&apos;)[0].text,</span><br><span class="line">        &apos;price&apos;: soup.select(&apos;span.price_now &gt; i&apos;)[0].text,</span><br><span class="line">        &apos;area&apos;: soup.select(&apos;div.palce_li &gt; span &gt; i &apos;)[0].text,</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"># 解析商家的商品详情</span><br><span class="line">def parse_shop_item_info(soup):</span><br><span class="line">    item_detail_tab.insert_one(&#123;</span><br><span class="line">        &apos;title&apos;: (soup.title.text).split(&apos;-&apos;)[0],</span><br><span class="line">        &apos;price&apos;: soup.select(&apos;div.su_con &gt; span.price&apos;)[0].text,</span><br><span class="line">        &apos;area&apos;: list(soup.select(&apos;.c_25d&apos;)[-1].stripped_strings),</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure>
<p>至此，我们所需要的数据就算是获取完毕，接下来我们需要做的就是根据需要来将数据进行整理，然后通过图表的方式来展示数据中包含的信息。</p>
<p><strong>第四步：</strong>这一步需要使用Highcharts来进行数据的展示，推荐使用Jupyter Notebook来进行操作，他可以直接将数据展示在网页上，极大地方便了数据查看。<br>Jupyter Notebook的安装和使用也很方便，网上也有很多的使用教程，直接附上其官网地址<strong><a href="http://jupyter.org/" target="_blank" rel="noopener">Jupyter NoteBook官网</a></strong>大家可以去查看</p>
<p>首先要获取商品的一个地区列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#首先获取数据库中的全部地区</span><br><span class="line">area_list = []</span><br><span class="line">for i in item_detail_tab.find():</span><br><span class="line">    area_list.append(i[&apos;area&apos;][0])</span><br><span class="line">#将全部地区放入set中进行去重，这样就得到一个全部地区的列表</span><br><span class="line">area_index = list(set(area_list))</span><br></pre></td></tr></table></figure></p>
<p>然后就是根据地区列表来统计每个地区的二手商品的数量（以发布商品的帖子数为记）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#统计每个地区的发帖数量</span><br><span class="line">post_times = []</span><br><span class="line">for index in area_index:</span><br><span class="line">    post_times.append(area_list.count(index))</span><br></pre></td></tr></table></figure>
<p>此时我们已经获取了商品的地区列表以及每个地区所对应的商品数量，需要做的就是将数据构造成Highcharts所要求的格式并进行展示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#定义一个迭代器函数来构造Highcharts所需要的数据格式</span><br><span class="line">def data_gen(types):</span><br><span class="line">    length = 0</span><br><span class="line">    if length  &lt;= len(area_index):</span><br><span class="line">        for area,times in zip(area_index,post_times):</span><br><span class="line">            data = &#123;</span><br><span class="line">                &apos;name&apos;:area,</span><br><span class="line">                &apos;data&apos;:[times],</span><br><span class="line">                &apos;type&apos;:types</span><br><span class="line">            &#125;</span><br><span class="line">            yield data</span><br><span class="line">            length += 1</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#将构造好的数据放入charts中进行展示</span><br><span class="line">seroes = [data for data in data_gen(&apos;column&apos;)]</span><br><span class="line">charts.plot(seroes,show=&apos;inline&apos;,options=dict(title=dict(text=&apos;最近7日发帖数量区域统计图&apos;)))</span><br></pre></td></tr></table></figure>
<p>至此我们就做了一个简易的爬虫来获取了一定的数据，并将结果进行了可视化的展示。</p>
<p><img src="https://img-blog.csdn.net/20180525153346206?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dxY19DU0RO/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="数据展示结果图"></p>
<h2 id="3-总结回顾"><a href="#3-总结回顾" class="headerlink" title="3.  总结回顾"></a>3.  总结回顾</h2><p>简单的总结一下在这个爬虫中我们所学到的一些东西：</p>
<ol>
<li>使用requests库进行网络请求</li>
<li>使用BeautifulSoup解析库对网页数据进行解析</li>
<li>学习如何通过selecter的方式选择网页中需要的元素</li>
<li>使用MongoDB进行数据的存储和读取</li>
<li>使用HighCharts对数据进行可视化的展示</li>
</ol>

    </div>
    
        <div class="reward" ontouchstart="">
    <div class="reward-wrap">赏
        <div class="reward-box">
            
                <span class="reward-type">
                    <img class="alipay" src="/img/reward-alipay.jpg"><b>支付宝打赏</b>
                </span>
            
            
                <span class="reward-type">
                    <img class="wechat" src="/img/reward-wepay.png"><b>微信打赏</b>
                </span>
            
        </div>
    </div>
    <p class="reward-tip">码字不易</p>
</div>


    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="" target="_blank">WeiQingcai</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2019/08/01/Seaborn学习笔记（二）/" class="pre-post btn btn-default" title="Seaborn学习笔记（二）">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">Seaborn学习笔记（二）</span>
        </a>
    
    
        <a href="/2019/08/01/《统计学习方法》笔记--提升方法/" class="next-post btn btn-default" title="统计学习方法--提升方法">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">统计学习方法--提升方法</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
<div id="lv-container" data-id="city" data-uid="MTAyMC8zMzA1MS85NjEz">
  <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];
         if (typeof LivereTower === 'function') { return; }
         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;
         e.parentNode.insertBefore(j, e);
     })(document, 'script');
  </script>
</div>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-整体思路流程"><span class="toc-text">1.  整体思路流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-简单代码演示"><span class="toc-text">2.  简单代码演示</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-准备工作"><span class="toc-text">1.  准备工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-对所需要的网页进行请求并解析返回的数据"><span class="toc-text">2.  对所需要的网页进行请求并解析返回的数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-对爬取到的数据进行存储和初步的可视化显示"><span class="toc-text">3.  对爬取到的数据进行存储和初步的可视化显示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-总结回顾"><span class="toc-text">3.  总结回顾</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
        访问量:
        <strong id="busuanzi_value_site_pv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
        &nbsp; | &nbsp;
        访客数:
        <strong id="busuanzi_value_site_uv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>




    <script src="/assets/tagcanvas.min.js?rev=2.9"></script>
    <script>
        var tagOption = {
            textColour: '#444', // 字体颜色
            outlineMethod: 'block', // 选中模式
            outlineColour: '#FFDAB9', // 选中模式的颜色
            interval: 30 || 30, // 动画帧之间的时间间隔，值越大，转动幅度越大
            textHeight: 13,
            outlineRadius: 3,
            freezeActive: true || '', // 选中的标签是否继续滚动
            frontSelect: true || '', // 不选标签云后部的标签
            initial: [0.1, -0.1],
            depth: 0.5,
            decel: 0.95,
            maxSpeed: 0.03,
            reverse: true || '', // 是否反向触发
            fadeIn: 500, // 进入动画时间
            wheelZoom: false || '' // 是否启用鼠标滚轮
        }
        TagCanvas.Start('tag-cloud-3d','',tagOption);
    </script>



    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/app.js?rev=@@hash"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>